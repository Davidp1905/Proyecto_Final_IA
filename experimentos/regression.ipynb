{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "97c1d256",
   "metadata": {},
   "source": [
    "Experimento con Regresión Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d7ed21c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar las bibliotecas necesarias\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import joblib\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2869ab79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar los datos\n",
    "train_df = pd.read_csv('../EDA/train.csv')\n",
    "test_df = pd.read_csv('../EDA/test.csv')\n",
    "validation_df = pd.read_csv('../EDA/val.csv')\n",
    "\n",
    "# Separar las características y la variable objetivo\n",
    "train_X = train_df.drop(columns=['WL'])\n",
    "train_Y = train_df['WL']\n",
    "\n",
    "test_X = test_df.drop(columns=['WL'])\n",
    "test_Y = test_df['WL']\n",
    "\n",
    "validation_X = validation_df.drop(columns=['WL'])\n",
    "validation_Y = validation_df['WL']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1bcb9c1",
   "metadata": {},
   "source": [
    "## Experimento con Regresión Logística\n",
    "\n",
    "Vamos a realizar un experimento usando regresión logística donde variaremos los hiperparámetros para encontrar la mejor configuración. Los hiperparámetros que ajustaremos son:\n",
    "\n",
    "- C: Inverso de la fuerza de regularización\n",
    "- solver: Algoritmo a usar en el problema de optimización\n",
    "- max_iter: Número máximo de iteraciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5569c7c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejores parámetros: {'C': 10, 'max_iter': 100, 'solver': 'liblinear'}\n",
      "Mejor accuracy en validación cruzada: 0.860210607190473\n"
     ]
    }
   ],
   "source": [
    "# Definir los parámetros para la búsqueda en cuadrícula\n",
    "param_grid = {\n",
    "    'C': [0.001, 0.01, 0.1, 1, 10],\n",
    "    'solver': ['lbfgs', 'liblinear', 'saga'],\n",
    "    'max_iter': [100, 200, 500]\n",
    "}\n",
    "\n",
    "# Crear el modelo base\n",
    "base_model = LogisticRegression(random_state=42)\n",
    "\n",
    "# Crear el objeto GridSearchCV\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=base_model,\n",
    "    param_grid=param_grid,\n",
    "    cv=5,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Ajustar el modelo usando GridSearchCV\n",
    "grid_search.fit(train_X, train_Y)\n",
    "\n",
    "# Mostrar los mejores parámetros y el mejor score\n",
    "print(\"Mejores parámetros:\", grid_search.best_params_)\n",
    "print(\"Mejor accuracy en validación cruzada:\", grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f44c7ab6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluación en conjunto de validación:\n",
      "Accuracy: 0.8655913978494624\n",
      "\n",
      "Matriz de Confusión:\n",
      "[[162  23]\n",
      " [ 27 160]]\n",
      "\n",
      "Reporte de Clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.88      0.87       185\n",
      "           1       0.87      0.86      0.86       187\n",
      "\n",
      "    accuracy                           0.87       372\n",
      "   macro avg       0.87      0.87      0.87       372\n",
      "weighted avg       0.87      0.87      0.87       372\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Obtener el mejor modelo\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Evaluar el modelo en el conjunto de validación\n",
    "val_pred = best_model.predict(validation_X)\n",
    "print(\"\\nEvaluación en conjunto de validación:\")\n",
    "print(\"Accuracy:\", accuracy_score(validation_Y, val_pred))\n",
    "print(\"\\nMatriz de Confusión:\")\n",
    "print(confusion_matrix(validation_Y, val_pred))\n",
    "print(\"\\nReporte de Clasificación:\")\n",
    "print(classification_report(validation_Y, val_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aa7c9747",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluación en conjunto de prueba:\n",
      "Accuracy: 0.851931330472103\n",
      "\n",
      "Matriz de Confusión:\n",
      "[[204  37]\n",
      " [ 32 193]]\n",
      "\n",
      "Reporte de Clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.85      0.86       241\n",
      "           1       0.84      0.86      0.85       225\n",
      "\n",
      "    accuracy                           0.85       466\n",
      "   macro avg       0.85      0.85      0.85       466\n",
      "weighted avg       0.85      0.85      0.85       466\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluar el modelo en el conjunto de prueba\n",
    "test_pred = best_model.predict(test_X)\n",
    "\n",
    "print(\"\\nEvaluación en conjunto de prueba:\")\n",
    "print(\"Accuracy:\", accuracy_score(test_Y, test_pred))\n",
    "print(\"\\nMatriz de Confusión:\")\n",
    "print(confusion_matrix(test_Y, test_pred))\n",
    "print(\"\\nReporte de Clasificación:\")\n",
    "print(classification_report(test_Y, test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0d3b258c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicción: 1\n",
      "Probabilidades: [0.04307014 0.95692986]\n"
     ]
    }
   ],
   "source": [
    "# Ejemplo de predicción con nuevos datos\n",
    "new_data = {\n",
    "    'W': [47], \n",
    "    'L': [30], \n",
    "    'W_PCT': [0.61], \n",
    "    'MIN': [240], \n",
    "    'FGM': [46], \n",
    "    'FGA': [84], \n",
    "    'FG_PCT': [0.548], \n",
    "    'FG3M': [22], \n",
    "    'FG3A': [40],\n",
    "    'FG3_PCT': [0.55], \n",
    "    'FTM': [12], \n",
    "    'FTA': [17], \n",
    "    'FT_PCT': [0.706], \n",
    "    'OREB': [8], \n",
    "    'DREB': [35], \n",
    "    'REB': [43], \n",
    "    'AST': [25], \n",
    "    'STL': [6],\n",
    "    'BLK': [2], \n",
    "    'TOV': [15], \n",
    "    'PF': [15], \n",
    "    'PTS': [126], \n",
    "    'year': [2025], \n",
    "    'month': [4], \n",
    "    'day': [6], \n",
    "    'team_analyzed': [11],\n",
    "    'local_team': [24],\n",
    "    'visitor_team': [11]\n",
    "}\n",
    "\n",
    "# Convertir los nuevos datos a DataFrame\n",
    "new_data_df = pd.DataFrame(new_data)\n",
    "\n",
    "# Realizar la predicción\n",
    "predicted_result = best_model.predict(new_data_df)\n",
    "predicted_prob = best_model.predict_proba(new_data_df)\n",
    "\n",
    "print(f\"Predicción: {predicted_result[0]}\")\n",
    "print(f\"Probabilidades: {predicted_prob[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bdead2ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo guardado como 'best_logistic_regression_model.pkl'\n"
     ]
    }
   ],
   "source": [
    "# Guardar el modelo\n",
    "joblib.dump(best_model, 'best_logistic_regression_model.pkl')\n",
    "print(\"Modelo guardado como 'best_logistic_regression_model.pkl'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1ceee3a",
   "metadata": {},
   "source": [
    "## Análisis de Resultados\n",
    "\n",
    "La regresión logística es un algoritmo más simple que Random Forest, pero puede ser efectivo para este tipo de clasificación binaria. Algunas observaciones importantes:\n",
    "\n",
    "1. La búsqueda en cuadrícula nos ayudó a encontrar los mejores hiperparámetros para el modelo.\n",
    "2. Podemos comparar el rendimiento con el modelo Random Forest anterior para ver qué enfoque funciona mejor.\n",
    "3. Las probabilidades de predicción nos dan una idea de la confianza del modelo en sus predicciones.\n",
    "\n",
    "Una ventaja de la regresión logística es que es más interpretable que Random Forest, ya que podemos analizar los coeficientes para entender la importancia relativa de cada característica. Además, la precisión que se obtuvo con este modelo fue de 0.851. Este resultado fue muy parecido al de SVC, estando a tan solo 0.005 por debajo. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "proyectoIAEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
